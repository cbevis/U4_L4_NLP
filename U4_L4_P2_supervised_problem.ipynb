{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW)\n",
    "Count how many times each word appears in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'. \n",
    "    text = re.sub(r'--',' ',text)\n",
    "    # get rid of text between brackets\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. \n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "alice_sents = [[sent, 'Carroll'] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen'] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the setnences from the two novels into one data frame\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add function to make stop words case insensitive\n",
    "stop_words_getter = lambda token: token.is_stop or token.lower_ in STOP_WORDS \n",
    "Token.set_extension('is_stop', getter=stop_words_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token._.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>correct</th>\n",
       "      <th>insolence</th>\n",
       "      <th>affliction</th>\n",
       "      <th>improve</th>\n",
       "      <th>busily</th>\n",
       "      <th>bow</th>\n",
       "      <th>oneself</th>\n",
       "      <th>action</th>\n",
       "      <th>relative</th>\n",
       "      <th>...</th>\n",
       "      <th>stage</th>\n",
       "      <th>benwick</th>\n",
       "      <th>occupy</th>\n",
       "      <th>bring</th>\n",
       "      <th>darkness</th>\n",
       "      <th>educate</th>\n",
       "      <th>ye</th>\n",
       "      <th>ancient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  year correct insolence affliction improve busily bow oneself action  \\\n",
       "0    0       0         0          0       0      0   0       0      0   \n",
       "1    0       0         0          0       0      0   0       0      0   \n",
       "2    0       0         0          0       0      0   0       0      0   \n",
       "3    0       0         0          0       0      0   0       0      0   \n",
       "4    0       0         0          0       0      0   0       0      0   \n",
       "\n",
       "  relative     ...     stage benwick occupy bring darkness educate ye ancient  \\\n",
       "0        0     ...         0       0      0     0        0       0  0       0   \n",
       "1        0     ...         0       0      0     0        0       0  0       0   \n",
       "2        0     ...         0       0      0     0        0       0  0       0   \n",
       "3        0     ...         0       0      0     0        0       0  0       0   \n",
       "4        0     ...         0       0      0     0        0       0  0       0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.to_csv('word_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9852664576802508\n",
      "\n",
      "Test set score: 0.8839285714285714\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence', 'text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=0)\n",
    "\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 3000) (3190,)\n",
      "Training set score: 0.9504702194357367\n",
      "\n",
      "Test set score: 0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8855799373040752\n",
      "\n",
      "Test set score: 0.8731203007518797\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0:\n",
    "Try to improve model performance. Other modeling techniques, more features, sentence-level features, contextual information, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.read_csv('word_counts.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>correct</th>\n",
       "      <th>insolence</th>\n",
       "      <th>affliction</th>\n",
       "      <th>improve</th>\n",
       "      <th>busily</th>\n",
       "      <th>bow</th>\n",
       "      <th>oneself</th>\n",
       "      <th>action</th>\n",
       "      <th>relative</th>\n",
       "      <th>...</th>\n",
       "      <th>stage</th>\n",
       "      <th>benwick</th>\n",
       "      <th>occupy</th>\n",
       "      <th>bring</th>\n",
       "      <th>darkness</th>\n",
       "      <th>educate</th>\n",
       "      <th>ye</th>\n",
       "      <th>ancient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  correct  insolence  affliction  improve  busily  bow  oneself  \\\n",
       "0     0        0          0           0        0       0    0        0   \n",
       "1     0        0          0           0        0       0    0        0   \n",
       "2     0        0          0           0        0       0    0        0   \n",
       "3     0        0          0           0        0       0    0        0   \n",
       "4     0        0          0           0        0       0    0        0   \n",
       "\n",
       "   action  relative     ...       stage  benwick  occupy  bring  darkness  \\\n",
       "0       0         0     ...           0        0       0      0         0   \n",
       "1       0         0     ...           0        0       0      0         0   \n",
       "2       0         0     ...           0        0       0      0         0   \n",
       "3       0         0     ...           0        0       0      0         0   \n",
       "4       0         0     ...           0        0       0      0         0   \n",
       "\n",
       "   educate  ye  ancient                                      text_sentence  \\\n",
       "0        0   0        0  Alice was beginning to get very tired of sitti...   \n",
       "1        0   0        0  So she was considering in her own mind (as wel...   \n",
       "2        0   0        0  There was nothing so VERY remarkable in that; ...   \n",
       "3        0   0        0                                           Oh dear!   \n",
       "4        0   0        0                                  I shall be late!'   \n",
       "\n",
       "   text_source  \n",
       "0      Carroll  \n",
       "1      Carroll  \n",
       "2      Carroll  \n",
       "3      Carroll  \n",
       "4      Carroll  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 words in this sentence, and 41 of them are unique.\n"
     ]
    }
   ],
   "source": [
    "# Text lost tokenization when written to csv\n",
    "example_sentence1 = nlp(word_counts['text_sentence'][0])\n",
    "\n",
    "# Look at some metrics around this sentence.\n",
    "example_words1 = [token for token in example_sentence1 if not token.is_punct]\n",
    "unique_words = set([token.text for token in example_words1])\n",
    "\n",
    "print((\"There are {} words in this sentence, and {} of them are\"\n",
    "       \" unique.\").format(len(example_words1), len(unique_words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts['text_sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_words(example_sentence):\n",
    "    # re-tokenize the sentences\n",
    "    example_sentence = nlp(example_sentence)\n",
    "    return [token for token in example_sentence if not token.is_punct]\n",
    "\n",
    "def sentence_unique(example_words):\n",
    "    return set([token.text for token in example_words])\n",
    "\n",
    "def sentence_length(example_words):\n",
    "    return len(example_words)\n",
    "    \n",
    "def count_punct(example_sentence):\n",
    "    # Not efficient to do this a second time\n",
    "    example_sentence = nlp(example_sentence)\n",
    "    punct = [token for token in example_sentence if token.is_punct]\n",
    "    return len(punct)\n",
    "\n",
    "def count_adj(example_words):\n",
    "    adj = [token for token in example_words if token.pos_ == 'ADJ']\n",
    "    return len(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['words'] = word_counts['text_sentence'].apply(sentence_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['len_words'] = word_counts['words'].apply(sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['unique_words'] = word_counts['words'].apply(sentence_unique)\n",
    "word_counts['len_unique'] = word_counts['unique_words'].apply(sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['num_punct'] = word_counts['text_sentence'].apply(count_punct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts['num_adj'] = word_counts['words'].apply(count_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>correct</th>\n",
       "      <th>insolence</th>\n",
       "      <th>affliction</th>\n",
       "      <th>improve</th>\n",
       "      <th>busily</th>\n",
       "      <th>bow</th>\n",
       "      <th>oneself</th>\n",
       "      <th>action</th>\n",
       "      <th>relative</th>\n",
       "      <th>...</th>\n",
       "      <th>ye</th>\n",
       "      <th>ancient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>words</th>\n",
       "      <th>len_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>len_unique</th>\n",
       "      <th>num_punct</th>\n",
       "      <th>num_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>[Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>57</td>\n",
       "      <td>{pictures, to, she, bank, thought, Alice, was,...</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>[So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>56</td>\n",
       "      <td>{she, feel, was, So, suddenly, pleasure, daisy...</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>[There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>29</td>\n",
       "      <td>{hear, to, was, Alice, so, out, Oh, Rabbit, de...</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>[Oh, dear]</td>\n",
       "      <td>2</td>\n",
       "      <td>{dear, Oh}</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>[I, shall, be, late]</td>\n",
       "      <td>4</td>\n",
       "      <td>{I, late, be, shall}</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  correct  insolence  affliction  improve  busily  bow  oneself  \\\n",
       "0     0        0          0           0        0       0    0        0   \n",
       "1     0        0          0           0        0       0    0        0   \n",
       "2     0        0          0           0        0       0    0        0   \n",
       "3     0        0          0           0        0       0    0        0   \n",
       "4     0        0          0           0        0       0    0        0   \n",
       "\n",
       "   action  relative   ...     ye  ancient  \\\n",
       "0       0         0   ...      0        0   \n",
       "1       0         0   ...      0        0   \n",
       "2       0         0   ...      0        0   \n",
       "3       0         0   ...      0        0   \n",
       "4       0         0   ...      0        0   \n",
       "\n",
       "                                       text_sentence  text_source  \\\n",
       "0  Alice was beginning to get very tired of sitti...      Carroll   \n",
       "1  So she was considering in her own mind (as wel...      Carroll   \n",
       "2  There was nothing so VERY remarkable in that; ...      Carroll   \n",
       "3                                           Oh dear!      Carroll   \n",
       "4                                  I shall be late!'      Carroll   \n",
       "\n",
       "                                               words  len_words  \\\n",
       "0  [Alice, was, beginning, to, get, very, tired, ...         57   \n",
       "1  [So, she, was, considering, in, her, own, mind...         56   \n",
       "2  [There, was, nothing, so, VERY, remarkable, in...         29   \n",
       "3                                         [Oh, dear]          2   \n",
       "4                               [I, shall, be, late]          4   \n",
       "\n",
       "                                        unique_words  len_unique  num_punct  \\\n",
       "0  {pictures, to, she, bank, thought, Alice, was,...          41         10   \n",
       "1  {she, feel, was, So, suddenly, pleasure, daisy...          46          7   \n",
       "2  {hear, to, was, Alice, so, out, Oh, Rabbit, de...          25          4   \n",
       "3                                         {dear, Oh}           2          1   \n",
       "4                               {I, late, be, shall}           4          2   \n",
       "\n",
       "   num_adj  \n",
       "0        3  \n",
       "1        7  \n",
       "2        2  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 3008 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence', 'text_source', 'words', 'unique_words', 'len_unique'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    Y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=0)\n",
    "params = {'C': np.arange(0.01,2,.05)}\n",
    "\n",
    "lr = LogisticRegression(max_iter=150, solver='liblinear')\n",
    "\n",
    "cv = GridSearchCV(lr, param_grid=params, cv=5)\n",
    "train = cv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043887147335423"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.6600000000000001}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_ `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9642633228840125\n",
      "Test score: 0.9191729323308271\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(solver='liblinear', C=1.66)\n",
    "lr2.fit(X_train, y_train)\n",
    "print('Training score: {}'.format(lr2.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lr2.score(X_test, y_test)))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1:\n",
    "See if new model is as good at identifying Alice in Wonderland vs. any other work, or Persuasion vs. any other work, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense = gutenberg.raw('austen-sense.txt')\n",
    "# The Chapter indicator is idiosyncratic\n",
    "sense = re.sub(r'CHAPTER \\d+', '', sense)\n",
    "sense = text_cleaner(sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_doc = nlp(sense)\n",
    "\n",
    "sense_sents = [[sent, 'Austen-Sense'] for sent in sense_doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(The, family, of, Dashwood, had, long, been, s...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Their, estate, was, large, ,, and, their, res...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(The, late, owner, of, this, estate, was, a, s...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(But, her, death, ,, which, happened, ten, yea...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(In, the, society, of, his, nephew, and, niece...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0             1\n",
       "0  (The, family, of, Dashwood, had, long, been, s...  Austen-Sense\n",
       "1  (Their, estate, was, large, ,, and, their, res...  Austen-Sense\n",
       "2  (The, late, owner, of, this, estate, was, a, s...  Austen-Sense\n",
       "3  (But, her, death, ,, which, happened, ten, yea...  Austen-Sense\n",
       "4  (In, the, society, of, his, nephew, and, niece...  Austen-Sense"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the setnences from the two novels into one data frame\n",
    "sentences = pd.DataFrame(sense_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (The, family, of, Dashwood, had, long, been, s...\n",
       "1       (Their, estate, was, large, ,, and, their, res...\n",
       "2       (The, late, owner, of, this, estate, was, a, s...\n",
       "3       (But, her, death, ,, which, happened, ten, yea...\n",
       "4       (In, the, society, of, his, nephew, and, niece...\n",
       "5          (His, attachment, to, them, all, increased, .)\n",
       "6       (The, constant, attention, of, Mr., and, Mrs.,...\n",
       "7       (By, a, former, marriage, ,, Mr., Henry, Dashw...\n",
       "8       (The, son, ,, a, steady, respectable, young, m...\n",
       "9       (By, his, own, marriage, ,, likewise, ,, which...\n",
       "10      (To, him, therefore, the, succession, to, the,...\n",
       "11      (Their, mother, had, nothing, ,, and, their, f...\n",
       "12      (The, old, gentleman, died, :, his, will, was,...\n",
       "13      (He, was, neither, so, unjust, ,, nor, so, ung...\n",
       "14      (Mr., Dashwood, had, wished, for, it, more, fo...\n",
       "15      (The, whole, was, tied, up, for, the, benefit,...\n",
       "16      (He, meant, not, to, be, unkind, ,, however, ,...\n",
       "17      (Mr., Dashwood, 's, disappointment, was, ,, at...\n",
       "18      (But, the, fortune, ,, which, had, been, so, t...\n",
       "19      (He, survived, his, uncle, no, longer, ;, and,...\n",
       "20      (His, son, was, sent, for, as, soon, as, his, ...\n",
       "21      (Mr., John, Dashwood, had, not, the, strong, f...\n",
       "22      (His, father, was, rendered, easy, by, such, a...\n",
       "23      (He, was, not, an, ill, -, disposed, young, ma...\n",
       "24      (Had, he, married, a, more, amiable, woman, ,,...\n",
       "25      (But, Mrs., John, Dashwood, was, a, strong, ca...\n",
       "26      (When, he, gave, his, promise, to, his, father...\n",
       "27      (He, then, really, thought, himself, equal, to...\n",
       "28      (The, prospect, of, four, thousand, a, -, year...\n",
       "29      (Yes, ,, he, would, give, them, three, thousan...\n",
       "                              ...                        \n",
       "5189          (What, immediately, followed, is, known, .)\n",
       "5190    (They, passed, some, months, in, great, happin...\n",
       "5191    (The, forgiveness, ,, at, first, ,, indeed, ,,...\n",
       "5192    (But, perseverance, in, humility, of, conduct,...\n",
       "5193    (Lucy, became, as, necessary, to, Mrs., Ferrar...\n",
       "5194    (They, settled, in, town, ,, received, very, l...\n",
       "5195    (What, Edward, had, done, to, forfeit, the, ri...\n",
       "5196    (It, was, an, arrangement, ,, however, ,, just...\n",
       "5197    (Elinor, 's, marriage, divided, her, as, littl...\n",
       "5198    (Mrs., Dashwood, was, acting, on, motives, of,...\n",
       "5199              (It, was, now, her, darling, object, .)\n",
       "5200    (Precious, as, was, the, company, of, her, dau...\n",
       "5201    (They, each, felt, his, sorrows, ,, and, their...\n",
       "5202    (With, such, a, confederacy, against, her, wit...\n",
       "5203    (Marianne, Dashwood, was, born, to, an, extrao...\n",
       "5204    (She, was, born, to, discover, the, falsehood,...\n",
       "5205    (She, was, born, to, overcome, an, affection, ...\n",
       "5206                                (But, so, it, was, .)\n",
       "5207    (Instead, of, falling, a, sacrifice, to, an, i...\n",
       "5208    (Colonel, Brandon, was, now, as, happy, ,, as,...\n",
       "5209    (Marianne, could, never, love, by, halves, ;, ...\n",
       "5210    (Willoughby, could, not, hear, of, her, marria...\n",
       "5211    (That, his, repentance, of, misconduct, ,, whi...\n",
       "5212    (But, that, he, was, for, ever, inconsolable, ...\n",
       "5213    (He, lived, to, exert, ,, and, frequently, to,...\n",
       "5214    (His, wife, was, not, always, out, of, humour,...\n",
       "5215    (For, Marianne, ,, however, in, spite, of, his...\n",
       "5216    (Mrs., Dashwood, was, prudent, enough, to, rem...\n",
       "5217    (Between, Barton, and, Delaford, ,, there, was...\n",
       "5218                                           (THE, END)\n",
       "Name: 0, Length: 5219, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_words = set(word_counts.columns[:-8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charm</th>\n",
       "      <th>canvas</th>\n",
       "      <th>rosetree</th>\n",
       "      <th>board</th>\n",
       "      <th>buy</th>\n",
       "      <th>share</th>\n",
       "      <th>faint</th>\n",
       "      <th>lane</th>\n",
       "      <th>talk</th>\n",
       "      <th>neglect</th>\n",
       "      <th>...</th>\n",
       "      <th>shoe</th>\n",
       "      <th>frog</th>\n",
       "      <th>dick</th>\n",
       "      <th>buttered</th>\n",
       "      <th>saucer</th>\n",
       "      <th>border</th>\n",
       "      <th>second</th>\n",
       "      <th>indignantly</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, family, of, Dashwood, had, long, been, s...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Their, estate, was, large, ,, and, their, res...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, late, owner, of, this, estate, was, a, s...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(But, her, death, ,, which, happened, ten, yea...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(In, the, society, of, his, nephew, and, niece...</td>\n",
       "      <td>Austen-Sense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  charm canvas rosetree board buy share faint lane talk neglect      ...       \\\n",
       "0     0      0        0     0   0     0     0    0    0       0      ...        \n",
       "1     0      0        0     0   0     0     0    0    0       0      ...        \n",
       "2     0      0        0     0   0     0     0    0    0       0      ...        \n",
       "3     0      0        0     0   0     0     0    0    0       0      ...        \n",
       "4     0      0        0     0   0     0     0    0    0       0      ...        \n",
       "\n",
       "  shoe frog dick buttered saucer border second indignantly  \\\n",
       "0    0    0    0        0      0      0      0           0   \n",
       "1    0    0    0        0      0      0      0           0   \n",
       "2    0    0    0        0      0      0      0           0   \n",
       "3    0    0    0        0      0      0      0           0   \n",
       "4    0    0    0        0      0      0      0           0   \n",
       "\n",
       "                                       text_sentence   text_source  \n",
       "0  (The, family, of, Dashwood, had, long, been, s...  Austen-Sense  \n",
       "1  (Their, estate, was, large, ,, and, their, res...  Austen-Sense  \n",
       "2  (The, late, owner, of, this, estate, was, a, s...  Austen-Sense  \n",
       "3  (But, her, death, ,, which, happened, ten, yea...  Austen-Sense  \n",
       "4  (In, the, society, of, his, nephew, and, niece...  Austen-Sense  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts_sense = bow_features(sentences, word_counts_words)\n",
    "word_counts_sense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_sense.to_csv('sense_word_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
