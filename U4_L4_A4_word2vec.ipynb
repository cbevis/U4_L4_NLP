{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import gensim\n",
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "- shallow neural network model for converting words to vectors using distributed representation\n",
    "- LSA creates vector representations of sentences based on words in them, word2vec creates representations of individual words, based on words around them\n",
    "- used when computers need to parse requests written by humans\n",
    "- 2 options, inverses of each other\n",
    "    - Continuous bag of words (CBOW)\n",
    "        - Identity of word predicted using words near it in a sentence\n",
    "    - skip-gram\n",
    "        - Identities of words are predicted from the word they surround, works better for large corpuses\n",
    "- 2 approaches to \"pushing\" vectors apart\n",
    "    - negative sampling: each time a word pulled toward some neighbors, the vectors for randomly chosen small set of other words pushed away\n",
    "    - hierarchical softmax: every neighboring word pulled closer or farther from a subset of words chosen based on a tree of possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash'--'\n",
    "    # Get rid of it now\n",
    "    \n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    \n",
    "    # Get rid of headings in square brackets\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    \n",
    "    # Get rid of chapter titles\n",
    "    text = re.sub(r'Chapter \\d+', '', text)\n",
    "    \n",
    "    # Get rid of extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Import all the Austen in the Project Gutenberg corpus\n",
    "austen = ''\n",
    "for novel in ['persuasion', 'emma', 'sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen = austen + work\n",
    "    \n",
    "# Clean the data\n",
    "austen_clean = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data.  This can take some time\n",
    "nlp = spacy.load('en')\n",
    "austen_doc1 = nlp(austen_clean[:1000000])\n",
    "austen_doc2 = nlp(austen_clean[1000000:2000000])\n",
    "austen_doc3 = nlp(austen_clean[2000000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who, for his own amusement, never took up any book but the Baronetage; there he found occupation for an idle hour, and consolation in a distressed one; there his faculties were roused into admiration and respect, by contemplating the limited remnant of the earliest patents; there any unwelcome sensations, arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century; and there, if every other leaf were powerless, he could read his own history with an interest which never failed. This was the page at which the favourite volume always opened: \"ELLIOT OF KELLYNCH HALL. \"Walter Elliot, born March 1, 1760, married, July 15, 1784, Elizabeth, daughter of James Stevenson, Esq. of South Park, in the county of Gloucester, by which lady (who died 1800) he has issue Elizabeth, born June 1, 1785; Anne, born August 9, 1787; a still-born son, November 5, 1789; M"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austen_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words\n",
    "\n",
    "sentences = []\n",
    "for sentence in austen_doc1.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "for sentence in austen_doc2.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "    \n",
    "for sentence in austen_doc3.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'daughter', 'eld', 'give', 'thing', 'tempt']\n",
      "We have 17854 sentences and 2006272 tokens.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,    # Number  of threads to run in parralel\n",
    "    min_count=10, # Min word count threshold\n",
    "    window=6,     # Number of words around target word to consider\n",
    "    sg=0,         # Use CBOW bc our corpus is small\n",
    "    sample=1e-3,  # Penalize frequent words\n",
    "    size=300,     # Word vector length\n",
    "    hs=1          # Use hierarchical softmax\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('people', 0.6582650542259216), ('daughter', 0.5567139387130737), ('introduction', 0.4640844464302063), ('prejudice', 0.4414145350456238), ('pleasing', 0.43370333313941956), ('thousand', 0.4336819648742676), ('person', 0.42792898416519165), ('joke', 0.4169720411300659), ('visit', 0.41186773777008057), ('friend', 0.40585067868232727)]\n"
     ]
    }
   ],
   "source": [
    "# List of words in model\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767084\n",
      "0.07640822\n",
      "marriage\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.wv.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill 0: Modify hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('farmer', 0.5917782783508301), ('rapid', 0.5804653167724609), ('husband', 0.5533252954483032), ('visit', 0.5447976589202881), ('house', 0.5397225618362427), ('people', 0.5167005658149719), ('settle', 0.5030304193496704), ('entertain', 0.4993135631084442), ('indisposition', 0.4963826537132263), ('brother', 0.48956024646759033)]\n",
      "0.63302493\n",
      "0.3267087\n",
      "marriage\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec(\n",
    "    sentences,    # Number  of threads to run in parralel\n",
    "    min_count=10, # Min word count threshold\n",
    "    window=10,    # Number of words around target word to consider\n",
    "    sg=0,         # Use CBOW bc our corpus is small\n",
    "    sample=1e-2,  # Penalize frequent words\n",
    "    size=300,     # Word vector length\n",
    "    hs=1          # Use hierarchical softmax\n",
    ")\n",
    "\n",
    "# List of words in model\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(model.wv.most_similar(positive=['lady', 'man'], negative=['woman']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('loud', 'aloud'))\n",
    "print(model.wv.similarity('mr', 'mrs'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.wv.doesnt_match(\"breakfast marriage dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Husband and brother are at least the right gender for the analogy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill 1: Word2Vec on 100B+ Words\n",
    "Because the models are so large, however, you may run into memory problems or crash the kernel. If you can't get a pretrained model to run locally, check out this interactive web app of the Google News model instead. https://rare-technologies.com/word2vec-tutorial/#bonus_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format ('./model/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
